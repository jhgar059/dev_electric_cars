#!/usr/bin/env python

import os
import logging
import sys
import pandas as pd
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func, text, inspect
from dotenv import load_dotenv

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - \"%(levelname)s\" - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("migrador")

# Importar expl√≠citamente el motor, base y modelos
try:
    from database import engine, SessionLocal, Base
    from models_sql import (
        AutoElectricoSQL, CargaSQL, EstacionSQL,
        AutoEliminadoSQL, CargaEliminadaSQL, EstacionEliminadaSQL
    )
except ImportError as e:
    logger.error(f"‚ùå Error al importar dependencias de DB/Modelos: {e}")
    sys.exit(1)


# ------------------ FUNCIONES DE CONVERSI√ìN (Correctas) ------------------

def conversion_tipo_auto(fila: pd.Series) -> AutoElectricoSQL:
    return AutoElectricoSQL(
        id=int(fila["id"]),
        marca=fila["marca"],
        modelo=fila["modelo"],
        anio=int(fila["anio"]),
        capacidad_bateria_kwh=float(fila["capacidad_bateria_kwh"]),
        autonomia_km=float(fila["autonomia_km"]),
        disponible=str(fila["disponible"]).lower() == "true",
        url_imagen=fila.get("url_imagen")
    )


def conversion_tipo_carga(fila: pd.Series) -> CargaSQL:
    return CargaSQL(
        id=int(fila["id"]),
        modelo_auto=fila["modelo_auto"],
        tipo_autonomia=fila["tipo_autonomia"],
        autonomia_km=float(fila["autonomia_km"]),
        consumo_kwh_100km=float(fila["consumo_kwh_100km"]),
        tiempo_carga_horas=float(fila["tiempo_carga_horas"]),
        dificultad_carga=fila["dificultad_carga"],
        requiere_instalacion_domestica=str(fila["requiere_instalacion_domestica"]).lower() == "true",
        url_imagen=fila.get("url_imagen")
    )


def conversion_tipo_estacion(fila: pd.Series) -> EstacionSQL:
    return EstacionSQL(
        id=int(fila["id"]),
        nombre=fila["nombre"],
        ubicacion=fila["ubicacion"],
        tipo_conector=fila["tipo_conector"],
        potencia_kw=float(fila["potencia_kw"]),
        num_conectores=int(fila["num_conectores"]),
        acceso_publico=str(fila["acceso_publico"]).lower() == "true",
        horario_apertura=fila["horario_apertura"],
        coste_por_kwh=float(fila["coste_por_kwh"]),
        operador=fila["operador"],
        url_imagen=fila.get("url_imagen")
    )


# ------------------ FUNCIONES DE DB (Limpieza y Secuencia) ------------------

def limpiar_tabla(db: Session, model_class, table_name: str):
    """Limpia la tabla usando TRUNCATE (PostgreSQL) para resetear el estado y evitar errores de ID."""
    try:
        # TRUNCATE es r√°pido y en PostgreSQL (Render) reinicia la secuencia autom√°ticamente.
        # CASCADE se usa si hay dependencias de foreign keys.
        db.execute(text(f"TRUNCATE TABLE {table_name} RESTART IDENTITY CASCADE;"))
        db.commit()
        logger.info(f"üóëÔ∏è Tabla '{table_name}' limpiada (TRUNCATE).")
    except Exception as e:
        logger.error(f"‚ùå Error al limpiar la tabla '{table_name}': {e}", exc_info=True)
        db.rollback()


def reset_sequence_ids(db: Session, model_class, table_name):
    """Funci√≥n de respaldo para resetear la secuencia de ID si TRUNCATE falla o no se usa CASCADE."""
    try:
        max_id = db.query(func.max(model_class.id)).scalar()
        if max_id is not None:
            sequence_name = f"{table_name}_id_seq"
            # setval(sequence_name, valor, is_called)
            # is_called=True significa que el pr√≥ximo valor ser√° max_id + 1
            db.execute(text(f"SELECT setval('{sequence_name}', {max_id}, true);"))
            db.commit()
            logger.info(f"‚úÖ Secuencia de ID para {table_name} reseteada a {max_id + 1}.")
    except Exception as e:
        logger.warning(
            f"‚ö†Ô∏è No se pudo resetear la secuencia de ID para {table_name} (Esto es normal si TRUNCATE RESTART IDENTITY funcion√≥): {e}")
        db.rollback()


# ------------------ FUNCI√ìN DE MIGRACI√ìN CON CHUNKING (Optimizado para Memoria) ------------------

def migrar_csv_a_db(filepath: str, ModelSQL, conversion_func):
    """
    Migra datos de un CSV a la base de datos en lotes (chunks) para ahorrar memoria.
    Esta funci√≥n asume que la tabla ya ha sido limpiada (TRUNCATE) previamente.
    """
    if not os.path.exists(filepath):
        logger.warning(f"‚ö†Ô∏è Archivo no encontrado: {filepath}. Saltando.")
        return

    logger.info(f"üîÑ Iniciando migraci√≥n por CHUNKS para {filepath} a la tabla {ModelSQL.__tablename__}...")

    try:
        # CLAVE: usar chunksize para procesar el archivo en peque√±os bloques
        chunksize = 1000
        total_inserted = 0

        # Leer el CSV en iterador de chunks
        for i, chunk in enumerate(pd.read_csv(filepath, chunksize=chunksize, encoding='utf-8', sep=',')):
            db = SessionLocal()  # Abre una nueva sesi√≥n para cada lote
            try:
                # 1. Convertir el chunk de Pandas a objetos de SQLAlchemy
                # Usar list comprehension es m√°s eficiente que iterrows() para esta conversi√≥n.
                data_to_insert = [ModelSQL(**conversion_func(row)) for index, row in chunk.iterrows()]

                # 2. Inserci√≥n masiva del lote (m√°s r√°pido que db.add() uno por uno)
                db.bulk_save_objects(data_to_insert)
                db.commit()
                total_inserted += len(data_to_insert)

            except Exception as e:
                db.rollback()
                logger.error(f"‚ùå Error cr√≠tico en LOTE {i + 1} de {filepath}. Revisar tipos de datos: {e}",
                             exc_info=True)
                # Si el error es cr√≠tico, paramos la migraci√≥n
                raise
            finally:
                db.close()  # Cierra la sesi√≥n

        logger.info(f"‚úÖ Migraci√≥n de {filepath} completa. Total de registros insertados: {total_inserted}.")

    except Exception as e:
        logger.error(f"‚ùå Error fatal al leer o procesar {filepath}: {e}", exc_info=True)


# ------------------ FUNCI√ìN PRINCIPAL (L√≥gica de Despliegue) ------------------

def main():
    """Funci√≥n principal para ejecutar la migraci√≥n: Limpiar, Migrar, Resetear."""
    # Asegurarse de que los directorios existan
    os.makedirs('datos', exist_ok=True)
    os.makedirs('eliminados', exist_ok=True)

    db = SessionLocal()
    try:
        # 1. LIMPIEZA CR√çTICA: TRUNCATE las tablas principales para una migraci√≥n limpia
        logger.info("--- INICIANDO LIMPIEZA DE TABLAS PRINCIPALES (TRUNCATE) ---")
        limpiar_tabla(db, AutoElectricoSQL, "autos_electricos")
        limpiar_tabla(db, CargaSQL, "cargas")
        limpiar_tabla(db, EstacionSQL, "estaciones_carga")
        logger.info("--- LIMPIEZA COMPLETADA ---")

    except Exception as e:
        logger.error(f"‚ùå Error al preparar la base de datos para migraci√≥n: {e}", exc_info=True)
        sys.exit(1)  # Detener si la limpieza falla
    finally:
        db.close()

    # 2. MIGRACI√ìN DE DATOS (Las tablas eliminadas no se limpian, solo se insertan si es un primer deploy)
    try:
        logger.info("--- INICIANDO MIGRACI√ìN DE DATOS PRINCIPALES ---")
        migrar_csv_a_db("datos/autos_electricos.csv", AutoElectricoSQL, conversion_tipo_auto)
        migrar_csv_a_db("datos/dificultad_carga.csv", CargaSQL, conversion_tipo_carga)
        migrar_csv_a_db("datos/estaciones_carga.csv", EstacionSQL, conversion_tipo_estacion)

        # Migrar tablas de eliminaci√≥n (simplemente se insertan, no se hace TRUNCATE/limpieza)
        logger.info("--- INICIANDO MIGRACI√ìN DE DATOS ELIMINADOS (Historial) ---")
        migrar_csv_a_db("eliminados/autos_eliminados.csv", AutoEliminadoSQL, conversion_tipo_auto)
        migrar_csv_a_db("eliminados/dificultad_carga_eliminados.csv", CargaEliminadaSQL, conversion_tipo_carga)
        migrar_csv_a_db("eliminados/estaciones_eliminadas.csv", EstacionEliminadaSQL, conversion_tipo_estacion)

    except Exception as e:
        logger.error(f"‚ùå FALLA CR√çTICA EN MIGRACI√ìN. El servicio probablemente morir√° con 500: {e}", exc_info=True)
        # No salimos aqu√≠ porque la aplicaci√≥n puede intentar arrancar incluso con datos parciales

    logger.info("‚ú® Migraci√≥n de CSV a DB completada.")


if __name__ == "__main__":
    main()